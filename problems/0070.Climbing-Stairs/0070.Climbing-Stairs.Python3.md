# [70. Climbing Stairs](https://leetcode.com/problems/climbing-stairs/solutions/4181234/climbing-stairs-python-easy-explanations/)

## Solution 1: Recursive Top-down Dynamic Programming

### Intuition

Break the problem into multiple overlapping subproblems with optimal substructures using top-down recursion, and solve them using dynamic programming.

Let `dp[i]` be the number of distinct ways to climb to the top of the stairs of height `i`. The recursive relation is defined as:

$$ \text{dp}[i] = \text{dp}[i-1] + \text{dp}[i-2] $$

and initialize `dp[0]` and `dp[1]` as 1, since we can either take 1 or 2 steps from the start.
> **_NOTE:_** similar to the [Fibonacci number](https://leetcode.com/problems/fibonacci-number/).

To prevent redundant repeated function calls, use memoization to cache the outputs.

### Approach

1. Create a recursive function with a cache to store the outputs of previous calls for memoization.
   > **_NOTE:_** we can use the `@functools.cache` decorator to help us cache the function outputs.
1. If a subproblem is already solved before, retrieve the result from the cache.
1. Define base case condition where `n < 2` and return `1`.
1. Call recursions on `n-1` and `n-2` as inputs, sum them up and store it into the cache.
1. Return the sum.

### Code

```python
class Solution:
    @functools.cache
    def climbStairs(self, n: int) -> int:
        if n < 2: return 1
        return self.climbStairs(n-1) + self.climbStairs(n-2)
```

### Complexity

- Time complexity: $O(n)$

  Each value from `0` till `n` is called and executed exactly once.

- Space complexity: $O(n)$

  - Recursive call stack requires $O(n)$ space.
  - Memoization cache requires $O(n)$ space.
  - So total space complexity is $O(2n) = O(n)$.

---

## Solution 2: Iterative Bottom-up Dynamic Programming

### Intuition

We can also build the dynamic programming table bottom-up using iteration.

We can optimize space as we do not need to keep track of the entire dynamic programming table values. We can just maintain two variables to store the previous two values `dp[i-1]` and `dp[i-2]`.

### Approach

1. Initialize two variables as `prev` and `curr` as `1`.
1. Iterative from `2` till `n`, and in each iteration, swap `prev` and `curr` as `curr` and `curr + prev`.
1. Finally, return `curr`.

### Code

```python
class Solution:
    def climbStairs(self, n: int) -> int:
        prev = curr = 1
        for _ in range(2, n + 1):
            prev, curr = curr, prev + curr
        return curr
```

### Complexity

- Time complexity: $O(n)$

  A single pass `for` loop is used to iterate from `2` till `n`.

- Space complexity: $O(1)$

  Constant space used (only 2 variables required).

---

## Solution 3: Matrix Exponentiation

### Intuition

Convert the recursive relation problem into a linear algebra problem and use the exponentiation by squaring technique for faster exponentiation (from $O(n)$ to $O(\log n)$).

First, define the base vector $F_1 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}$ and transformation matrix $T = \begin{bmatrix} 0 & 1 \\ 1 & 1 \end{bmatrix}$.

Then, we can follow the recursion relation to find the subsequent vectors in the sequence:

$$F_2 = TF_1 = \begin{bmatrix}
   0 & 1 \\
   1 & 1
\end{bmatrix}\begin{bmatrix}
   1 \\
   1
\end{bmatrix} = \begin{bmatrix}
   1 \\
   2
\end{bmatrix}$$

$$F_3 = TF_2 = \begin{bmatrix}
   0 & 1 \\
   1 & 1
\end{bmatrix}\begin{bmatrix}
   1 \\
   2
\end{bmatrix} = \begin{bmatrix}
   2 \\
   3
\end{bmatrix}$$
$$...$$
with the general closed form as:
$$F_n = TF_{n-1} =  T^{n-1}F_1$$

Use the exponentiation by squaring technique (also known as Fast Power algorithm) to calculate $C=T^{n-1}$. This technique utilize matrix multiplication to reduce the exponent by half each time hence reducing time complexity.

Return the last element of $CF_1$ as the final result.

### Approach

1. Implement `multiply()` function that takes in two input square matrices `A` and `B` of equal size and return their multiplied result.
   - Get the size of the matrices as `K`, and initialize the output matrix `C` of size `K x K` with `0` values.
   - Iterate over `K` thrice with `i`, `j`, `k` as index pointers, and update `C[i][j] += A[i][k] * B[k][j]`.
1. Implement `powerBySquaring()` function that takes in a square matrix `A` and an exponent `n` and return `A` raised to the power of `n`.
   - Define base condition where `n == 1`, and return `A`.
   - If `n` is odd, call recursion with exponent as `n-1` and return multiply `A` with the result.
   - Else `n` is even, call recursion with exponent as `n // 2`, and return multiply `A` with the result.
1. In the main function:
   - Define base case if `n < 2` and return `1`.
   - Initialize base vector `F1 = [1, 1]` and transformation matrix `T = [[0, 1], [1, 1]]`.
   - Compute `C` by calling `powerBySquaring(T, n-1)`.
   - Return the last element of `CF1` which is `C[1][0] * F1[0] + C[1][1] * F1[1]`.

### Code

```python
class Solution:
    def climbStairs(self, n: int) -> int:
        if n < 2: return 1
        F1 = [1, 1]
        T = [[0, 1],
             [1, 1]]
        C = self.powerBySquaring(T, n - 1)
        return C[1][0] * F1[0] + C[1][1] * F1[1]

    def multiply(self, A, B):  # where A and B are square matrices
        K = len(A)
        C = [[0] * K for _ in range(K)]
        for i in range(K):
            for j in range(K):
                for k in range(K):
                    C[i][j] += A[i][k] * B[k][j]
        return C

    def powerBySquaring(self, A, n):
        if n == 1: return A
        if n % 2 != 0:  # odd
            return self.multiply(A, self.powerBySquaring(A, n - 1))
        else:  # even
            A = self.powerBySquaring(A, n // 2)
            return self.multiply(A, A)
```

### Complexity

- Time complexity: $O(\log n)$

  - `multiply()` function takes $O(K^3) = O(2^3) = O(1)$ time, since $K$ is always 2.
    > **_NOTE:_** there exists faster algorithms for matrix multiplication that takes $O(K^{2.37})$ time but it is unnecessary since $K$ is constant in this case.
  - `powerBySquaring()` function takes $O(\log n)$ time, since the exponent $n$ is constantly halved, and thus `multiply()` is called at most $\log_2 n + 1$ times.
  - The product of `C` with `f1` also takes $O(1)$ time since their size is always a constant `2`.
  - So overall time complexity is $O(\log n)$.

- Space complexity: $O(1)$

  Constant space used (only a `2x1` vector and `2x2` matrix is required).
